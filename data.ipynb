{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "## Major\n",
    "- [x] create term-by-document matrix (calculate words frequncies for each term-document pair)\n",
    " - [ ] check that it's actually correct - especially if we don't map terms to wrong documents\n",
    "- [x] convert term-by-document frequencies to tf-idf (calcualte tf-idf for each term-document pair)\n",
    " - [ ] check\n",
    "- [ ] we may need actual (numpy?) matrix?\n",
    "- [ ] LSI magic\n",
    "\n",
    "### Minor\n",
    "- [x] remove numbers from terms - done but not sure if it's good thing to do, maybe it's also important for relevancy of docs,\n",
    "like for example when there is year written?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_data = pd.read_csv(\"articles.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author claps  reading_time  \\\n",
       "0  Justin Lee  8.3K            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_docs(docs, use_lemmatizer = True):\n",
    "    '''Tokenize and preprocess documents\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    use_lemmatizer : bool\n",
    "                     Uses lemmazizer if True, othrerwise uses stemmer.\n",
    "    '''\n",
    "    preproccessed_docs = []\n",
    "    \n",
    "    # English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    \n",
    "    # Word tokenizer that removes punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    # lemmatizer / Stemmer\n",
    "    if use_lemmatizer:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "    else:\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    for row in docs.itertuples(index=True, name='Doc'):\n",
    "        text = row.text\n",
    "        \n",
    "        # remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        text_words = tokenizer.tokenize(text)\n",
    "        \n",
    "        if use_lemmatizer:\n",
    "            text_words = [lemmatizer.lemmatize(word, pos=\"v\").lower() for word in text_words\n",
    "                          if word not in string.punctuation and word.lower() not in en_stop]\n",
    "        else:\n",
    "            text_words = [stemmer.stem(word).lower() for word in text_words\n",
    "                         if word not in string.punctuation and word.lower() not in en_stop]\n",
    "        \n",
    "        preproccessed_docs.append({'words': text_words})\n",
    "    \n",
    "    pdocs = pd.DataFrame(preproccessed_docs)\n",
    "    return pdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[oh, headline, blare, chatbots, next, big, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ever, find, look, question, concept, syntax, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[machine, learn, increasingly, move, hand, des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[understand, machine, learning, big, question,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[want, learn, apply, artificial, intelligence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>[click, share, article, linkedin, skip, part, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>[opinions, deep, neural, network, machine, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>[everyone, remotely, tune, recent, progress, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>[one, biggest, misconceptions, around, idea, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>[believe, psychologist, philosopher, brain, li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 words\n",
       "0    [oh, headline, blare, chatbots, next, big, thi...\n",
       "1    [ever, find, look, question, concept, syntax, ...\n",
       "2    [machine, learn, increasingly, move, hand, des...\n",
       "3    [understand, machine, learning, big, question,...\n",
       "4    [want, learn, apply, artificial, intelligence,...\n",
       "..                                                 ...\n",
       "332  [click, share, article, linkedin, skip, part, ...\n",
       "333  [opinions, deep, neural, network, machine, lea...\n",
       "334  [everyone, remotely, tune, recent, progress, m...\n",
       "335  [one, biggest, misconceptions, around, idea, d...\n",
       "336  [believe, psychologist, philosopher, brain, li...\n",
       "\n",
       "[337 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preproccessed_docs = preprocess_docs(bp_data)\n",
    "display(preproccessed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_by_document_frequency(preprocessed_docs):\n",
    "    document_by_term = {}\n",
    "    \n",
    "    for index, row in preprocessed_docs.iterrows():\n",
    "        doc_id = index\n",
    "        doc_words = row['words']\n",
    "        \n",
    "        # computed later, @TODO: move computation here and fix below or remove\n",
    "#         document_by_term[doc_id] = {\n",
    "#             'total_words': len(doc_words)\n",
    "#         }\n",
    "        document_by_term[doc_id] = {}\n",
    "        \n",
    "        for word in set(row['words']):\n",
    "            document_by_term[doc_id][word] = doc_words.count(word)\n",
    "\n",
    "    df = pd.DataFrame(document_by_term)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequency = get_term_by_document_frequency(preproccessed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behind</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paradoxes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initialisation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intelligible</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illusion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularisation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16603 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1    2    3    4    5    6    7    8    9    ...  327  \\\n",
       "wait            1.0  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  ...  1.0   \n",
       "fair            1.0  NaN  NaN  1.0  NaN  NaN  NaN  NaN  1.0  NaN  ...  3.0   \n",
       "request         1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  ...  NaN   \n",
       "behind          1.0  NaN  1.0  NaN  2.0  NaN  NaN  NaN  NaN  4.0  ...  1.0   \n",
       "speech          2.0  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  ...  NaN   \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "paradoxes       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN   \n",
       "initialisation  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN   \n",
       "intelligible    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN   \n",
       "illusion        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN   \n",
       "regularisation  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN   \n",
       "\n",
       "                328  329  330  331  332  333  334  335  336  \n",
       "wait            NaN  1.0  NaN  NaN  1.0  NaN  NaN  NaN  NaN  \n",
       "fair            NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  \n",
       "request         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "behind          NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "speech          NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  \n",
       "...             ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "paradoxes       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  \n",
       "initialisation  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  2.0  \n",
       "intelligible    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  \n",
       "illusion        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  \n",
       "regularisation  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  3.0  \n",
       "\n",
       "[16603 rows x 337 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_terms(df_frequency, max_df=1, min_df=0, max_terms=None):\n",
    "    '''Remove unimportant terms from term-by-document matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    max_df : float , between [0, 1]\n",
    "             Terms that appear in more % of documents will be ignored\n",
    "    min_df : float , between [0, 1]\n",
    "             Terms that appear in less % of documents will be ignored\n",
    "    max_terms : int , None\n",
    "                If not None, only top `max_terms` terms will be returned.\n",
    "    '''\n",
    "    df = df_frequency.copy()\n",
    "    if 'doc_frequency' in df:\n",
    "        df = df.drop(columns='doc_frequency')\n",
    "    \n",
    "    corpus_size = df.shape[1]\n",
    "    \n",
    "    df['doc_frequency'] = df_frequency.fillna(0).astype(bool).sum(axis=1) / corpus_size\n",
    "    \n",
    "    df = df[df.doc_frequency <= max_df]\n",
    "    df = df[df.doc_frequency >= min_df]\n",
    "    \n",
    "    if max_terms is not None:\n",
    "        assert('not implementd' == False) # @TODO - implement or remove\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16603, 338)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_terms(df_frequency).sort_values('doc_frequency', ascending=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>doc_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>take</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.777448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.765579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.762611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.756677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsupervised</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encourage</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1090 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1     2     3    4    5     6    7    8    9  ...  328  \\\n",
       "take          7.0  3.0   4.0   5.0  9.0  2.0   NaN  4.0  NaN  5.0  ...  5.0   \n",
       "way           9.0  1.0   1.0   2.0  4.0  4.0   2.0  2.0  2.0  9.0  ...  NaN   \n",
       "find          NaN  3.0   2.0   3.0  1.0  3.0   1.0  2.0  1.0  7.0  ...  3.0   \n",
       "machine       6.0  2.0  10.0  11.0  2.0  NaN  20.0  3.0  2.0  5.0  ...  2.0   \n",
       "need          3.0  1.0   5.0   2.0  6.0  3.0   1.0  NaN  NaN  7.0  ...  9.0   \n",
       "...           ...  ...   ...   ...  ...  ...   ...  ...  ...  ...  ...  ...   \n",
       "max           NaN  NaN   NaN   NaN  NaN  NaN   NaN  NaN  NaN  NaN  ...  1.0   \n",
       "unsupervised  NaN  NaN   NaN   NaN  NaN  NaN   1.0  NaN  1.0  1.0  ...  NaN   \n",
       "ideal         1.0  NaN   NaN   NaN  NaN  NaN   NaN  NaN  NaN  1.0  ...  NaN   \n",
       "encourage     NaN  NaN   1.0   NaN  3.0  NaN   NaN  NaN  NaN  NaN  ...  NaN   \n",
       "setup         1.0  NaN   NaN   NaN  NaN  NaN   NaN  NaN  NaN  NaN  ...  NaN   \n",
       "\n",
       "               329  330  331  332   333  334  335  336  doc_frequency  \n",
       "take           2.0  NaN  6.0  2.0   1.0  4.0  NaN  3.0       0.777448  \n",
       "way           11.0  NaN  5.0  1.0   1.0  NaN  1.0  7.0       0.765579  \n",
       "find           5.0  NaN  4.0  3.0   2.0  NaN  NaN  5.0       0.762611  \n",
       "machine        8.0  2.0  1.0  6.0  11.0  4.0  4.0  NaN       0.762611  \n",
       "need           7.0  6.0  6.0  6.0  10.0  1.0  3.0  4.0       0.756677  \n",
       "...            ...  ...  ...  ...   ...  ...  ...  ...            ...  \n",
       "max            NaN  NaN  NaN  2.0   NaN  NaN  NaN  NaN       0.100890  \n",
       "unsupervised   NaN  NaN  NaN  NaN   2.0  1.0  NaN  NaN       0.100890  \n",
       "ideal          NaN  NaN  NaN  NaN   NaN  NaN  NaN  NaN       0.100890  \n",
       "encourage      NaN  NaN  NaN  1.0   NaN  NaN  NaN  NaN       0.100890  \n",
       "setup          NaN  NaN  NaN  1.0   NaN  NaN  NaN  NaN       0.100890  \n",
       "\n",
       "[1090 rows x 338 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_terms(df_frequency, 0.8, 0.1).sort_values('doc_frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = reduce_terms(df_frequency, 0.8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(df_frequency):\n",
    "    df = df_frequency.copy()\n",
    "    # tf := word frequency / total frequency\n",
    "    df.loc['total_words'] = df.sum()\n",
    "    \n",
    "    df = df.drop('total_words')[:] / df.loc['total_words']\n",
    "    \n",
    "    # idf := log ( len(all_documents) / len(documents_containing_word) )\n",
    "    \n",
    "    corpus_size = df.shape[1]\n",
    "\n",
    "    # number of non-zero cols\n",
    "    df['doc_frequency'] = df.fillna(0).astype(bool).sum(axis=1)\n",
    "        \n",
    "    df['idf'] = np.log( corpus_size / df['doc_frequency'] )\n",
    "    \n",
    "    # tf-idf := tf * idf\n",
    "    _cols = df.columns.difference(['idf', 'doc_frequency'])\n",
    "    df[_cols] = df[_cols].multiply(df[\"idf\"], axis=\"index\")\n",
    "    \n",
    "    df.drop(columns=['doc_frequency', 'idf'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>0.001356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>0.001535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behind</th>\n",
       "      <td>0.000953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.002525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuron</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.028602</td>\n",
       "      <td>0.008836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavior</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvements</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1090 rows × 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5    \\\n",
       "wait          0.001356       NaN       NaN       NaN  0.001116       NaN   \n",
       "fair          0.001535       NaN       NaN  0.002239       NaN       NaN   \n",
       "behind        0.000953       NaN  0.000855       NaN  0.001569       NaN   \n",
       "speech        0.002525       NaN       NaN       NaN       NaN       NaN   \n",
       "come          0.000739  0.000771  0.000221  0.001078  0.000203  0.000911   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "movie              NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "neuron             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "behavior           NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "improvements       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "keras              NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                   6         7         8         9    ...       327  328  \\\n",
       "wait               NaN       NaN       NaN       NaN  ...  0.000502  NaN   \n",
       "fair               NaN       NaN  0.003436       NaN  ...  0.001705  NaN   \n",
       "behind             NaN       NaN       NaN  0.002479  ...  0.000353  NaN   \n",
       "speech        0.002311       NaN       NaN       NaN  ...       NaN  NaN   \n",
       "come          0.000451  0.002076  0.001655  0.000961  ...  0.000547  NaN   \n",
       "...                ...       ...       ...       ...  ...       ...  ...   \n",
       "movie              NaN       NaN       NaN       NaN  ...       NaN  NaN   \n",
       "neuron             NaN       NaN       NaN       NaN  ...  0.000542  NaN   \n",
       "behavior           NaN       NaN       NaN       NaN  ...       NaN  NaN   \n",
       "improvements       NaN       NaN       NaN       NaN  ...       NaN  NaN   \n",
       "keras              NaN       NaN       NaN       NaN  ...       NaN  NaN   \n",
       "\n",
       "                   329       330      331       332       333       334  \\\n",
       "wait          0.001366       NaN      NaN  0.001665       NaN       NaN   \n",
       "fair               NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "behind             NaN  0.002651      NaN       NaN       NaN       NaN   \n",
       "speech             NaN       NaN      NaN       NaN  0.001261       NaN   \n",
       "come          0.000248       NaN  0.00062  0.000907       NaN       NaN   \n",
       "...                ...       ...      ...       ...       ...       ...   \n",
       "movie              NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "neuron             NaN       NaN      NaN       NaN       NaN  0.011939   \n",
       "behavior           NaN       NaN      NaN       NaN       NaN  0.004026   \n",
       "improvements  0.003168       NaN      NaN       NaN       NaN       NaN   \n",
       "keras         0.012671       NaN      NaN       NaN       NaN       NaN   \n",
       "\n",
       "                   335       336  \n",
       "wait               NaN       NaN  \n",
       "fair               NaN  0.001543  \n",
       "behind             NaN       NaN  \n",
       "speech             NaN       NaN  \n",
       "come               NaN  0.000495  \n",
       "...                ...       ...  \n",
       "movie              NaN       NaN  \n",
       "neuron        0.028602  0.008836  \n",
       "behavior      0.015782       NaN  \n",
       "improvements  0.005585       NaN  \n",
       "keras              NaN       NaN  \n",
       "\n",
       "[1090 rows x 337 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tf_idf = get_tf_idf(df_reduced)\n",
    "display(df_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0013562 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00153473, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.0015434 ],\n",
       "       [0.00095305, 0.        , 0.00085462, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.00402571, 0.0157816 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00558486,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = df_tf_idf.fillna(0).to_numpy()\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(values, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.38027008e-02, -4.52527257e-02, -5.49950587e-02, ...,\n",
       "        -5.03892281e-02, -5.13812996e-02, -5.13567737e-02],\n",
       "       [ 1.20471112e-02,  9.93265786e-03,  8.84456061e-03, ...,\n",
       "         1.38319783e-02,  1.34522571e-02,  1.30991734e-02],\n",
       "       [-4.57748185e-03, -7.51473102e-03, -1.46184934e-02, ...,\n",
       "        -1.57943086e-02, -1.00991313e-02, -1.59776393e-02],\n",
       "       ...,\n",
       "       [ 0.00000000e+00, -1.83744577e-17, -3.12236288e-17, ...,\n",
       "        -3.51281504e-17, -3.46944695e-18, -5.89805982e-17],\n",
       "       [ 0.00000000e+00, -2.78299028e-16, -1.27006870e-16, ...,\n",
       "         2.42861287e-17,  6.93889390e-18,  5.81132364e-17],\n",
       "       [ 8.16481618e-01,  1.94289029e-16, -3.88578059e-16, ...,\n",
       "         7.25060203e-18, -3.83570400e-17, -4.23245423e-17]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
